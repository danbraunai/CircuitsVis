{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # Fetching activations from a pretrained model\n","\n"," This notebook allows you to pass any text through a pretrained huggingface model, and visualise the resulting activations using circuitvis.\n","\n"," If using the latest public release of [circuitsvis](https://github.com/alan-cooney/CircuitsVis), you can install with `pip install circuitsvis && yarn add circuitsvis`.\n","\n"," If using a development version, clone the desired repo and run `pip install -e python && cd react && yarn` (you may also use `cd python && poetry install --with dev` if using poetry)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import subprocess\n","# Install the required packages for this script (these aren't included in the project's poetry dependencies)\n","print(\n","    subprocess.check_output(\n","        \"pip install transformers torch\",\n","        shell=True,\n","    )\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from functools import partial\n","from typing import Union\n","import torch\n","import numpy as np\n","from transformers import GPT2LMHeadModel, GPT2TokenizerFast, PreTrainedModel, PreTrainedTokenizerFast\n","from circuitsvis.activations import text_neuron_activations\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ### Functions for loading model and fetching activations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def load_model_tokenizer(model_name: str) -> tuple[PreTrainedModel, PreTrainedTokenizerFast]:\n","    \"\"\"Load a pretrained model and tokenizer from huggingface.\n","    \n","    Args:\n","        model_name: The name of the pretrained model to load.\n","        \n","    Returns:\n","        model: The loaded model.\n","        tokenizer: The loaded tokenizer.\n","    \"\"\"\n","    model = GPT2LMHeadModel.from_pretrained(model_name)\n","    tokenizer = GPT2TokenizerFast.from_pretrained(model_name)\n","    tokenizer.pad_token = tokenizer.eos_token\n","    model.eval()\n","    return model, tokenizer\n","\n","\n","def fetch_activations(model: PreTrainedModel, tokenizer: PreTrainedTokenizerFast, text: Union[list[str], str], layers: list, neurons: list) -> tuple[list[list[str]], list[np.ndarray]]:\n","    \"\"\"Fetch activations from a model.\n","\n","    Args:\n","        model: The model to fetch activations from.\n","        tokenizer: The PreTrainedTokenizerFast tokenizer to use.\n","        text: String or list of strings to pass to the model.\n","        layers: The layers to fetch activations from.\n","        neurons: The neurons to fetch activations from.\n","\n","    Returns:\n","        tokens: Nested list of tokens, one list per sample in the batch.\n","        activations: List of the ndarrays representing the model activations for each sample (n_tokens, n_layers, n_neurons)\n","    \"\"\"\n","    if isinstance(text, str):\n","        # Batch size of 1\n","        text = [text]\n","\n","    # Tokenize the input text with padding to the longest sequence in the batch\n","    tokenized = tokenizer(text, padding=True, return_tensors=\"pt\", return_offsets_mapping=True)\n","    # Get the individual tokens from the offsets\n","    tokens = [[text[sample_idx][i:j] for i, j in offsets] for sample_idx, offsets in enumerate(tokenized[\"offset_mapping\"])]\n","\n","    # setup hooks\n","    save_ctx = {}\n","    def _save_output_hook(self, inputs, output, layer_num, neurons):\n","        save_ctx[layer_num] = output[\n","            0\n","        ][:,:,neurons].detach()  # gpt2 block output is a tuple where the 0th element is the residual stream\n","\n","    handles = []\n","    for layer_idx in layers:\n","        handles.append(\n","            model.transformer.h[layer_idx].register_forward_hook(\n","                partial(_save_output_hook, layer_num=layer_idx, neurons=neurons)\n","            )\n","        )\n","    # Run through model\n","    with torch.inference_mode():\n","        model(input_ids=tokenized[\"input_ids\"], attention_mask=tokenized[\"attention_mask\"])\n","\n","    # Remove hook handles from model\n","    for handle in handles:\n","        handle.remove()\n","\n","    # Stack the activations from all layers\n","    activations = torch.stack([save_ctx[layer_idx] for layer_idx in layers], dim=2)  # (batch_size, padded_seq_length, n_layers, n_neurons)\n","\n","    # Remove the padding tokens and their corresponding activations\n","    activations_list = []\n","    tokens_list = []\n","    for sample_idx, token in enumerate(tokens):\n","        num_tokens = tokenized[\"attention_mask\"][sample_idx].sum().item()\n","        activations_list.append(activations[sample_idx, :num_tokens].numpy())\n","        tokens_list.append(token[:num_tokens])\n","    return tokens_list, activations_list\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["##### Enter your parameters here\n","model_name = \"gpt2\"\n","layers = [0, 1]\n","neurons = [3, 4, 5]\n","# TODO: Add support for activation positions other than residual"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model, tokenizer = load_model_tokenizer(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["text_batch = [\"Here is some text that we will get activations for.\", \"more text\"]\n","tokens, acts = fetch_activations(model, tokenizer, text_batch, layers, neurons)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Visualise the activations in the notebook\n","vis = text_neuron_activations(tokens=tokens, activations=acts)\n","vis\n","\n","# If you wish to view this visualisation in a browser, uncomment the below to save the vis to an html file which you can open in a browser\n","# vis_path = \"./vis.html\"\n","# with open(vis_path, \"w\") as f:\n","#     f.write(vis._repr_html_())"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}